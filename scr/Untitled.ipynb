{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D # <--- This is important for 3d plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lake4550re_data = pd.read_csv('obective_values_4obj_5scen(Eker)_50re-evaluate1000(13.10.2020)SLSQP.csv') \n",
    "Lake4550re_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LakeEker_re_data = pd.read_csv('Eker_50solutions_re-evaluate1000(29.3.2021)SLSQP.csv') \n",
    "LakeEker_re_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = Lake4550re_data\n",
    "\n",
    "n = 50 #non-dominated solutions\n",
    "ss=1000 # scenarios\n",
    "\n",
    "nnUtility = np.zeros((n,ss))\n",
    "nnPollution = np.zeros((n,ss))\n",
    "nnInertia = np.zeros((n,ss))\n",
    "nnReliability = np.zeros((n,ss))\n",
    "\n",
    "for p in range(ss):\n",
    "    for i in range(n):\n",
    "        nnUtility[i][p] = df.loc[i*1000+p,'Utility']\n",
    "        nnPollution[i][p] = df.loc[i*1000+p,'Pollution']\n",
    "        nnInertia[i][p] = df.loc[i*1000+p,'Inertia']\n",
    "        nnReliability[i][p] = df.loc[i*1000+p,'Reliability']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pcritical = pd.read_csv('Pcrit(EkerBarth)_50solutions_random_rfps(15.10.2020)5scen.csv')\n",
    "#Pcritical.describe()\n",
    "\n",
    "Pcriti = np.zeros((n,ss))\n",
    "ind = 0\n",
    "for j in range(n):\n",
    "    for p in range(ss):\n",
    "        Pcriti[j][p] = Pcritical['Pcrit'][ind]\n",
    "        ind += 1\n",
    "    \n",
    "#Pcriti[49][999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Robustness analysis --> B\n",
    "Calculating how many scenarios has \n",
    "    B.1) reliability > 0.8 \n",
    "    B.2) Utility > 0.2/0.1 ?\n",
    "    B.3) Both a and b.\n",
    "\n",
    "\"\"\"\n",
    "n_reliabale_scen = np.zeros((n,))\n",
    "n_high_eco_scen = np.zeros((n,))\n",
    "n_both_scen = np.zeros((n,))\n",
    "n_high_inertia_scen = np.zeros((n,))\n",
    "n_low_pollution_scen = np.zeros((n,))\n",
    "#critical_scen = []\n",
    "\n",
    "\n",
    "for i in range(n): \n",
    "    nrs = 0\n",
    "    nhes = 0\n",
    "    nboth = 0\n",
    "    nhi = 0\n",
    "    nlp = 0\n",
    "    for p in range(ss):\n",
    "        if nnReliability[i][p]>.8: #A.1\n",
    "            nrs += 1\n",
    "        #else:\n",
    "        #    critical_scen.append(np.array([p+1, b[p], q[p], mean[p], stdev[p], delta[p]]) )  \n",
    "        if nnUtility[i][p]>0.2: #A.2\n",
    "            nhes += 1\n",
    "        if nnReliability[i][p]>0.8 and nnUtility[i][p]>0.2: #A.3\n",
    "            nboth += 1\n",
    "        if nnInertia[i][p]>0.99:\n",
    "            nhi += 1   \n",
    "        if nnPollution[i][p]<Pcriti[i][p]:\n",
    "            nlp += 1\n",
    "            \n",
    "    n_reliabale_scen[i] = nrs   \n",
    "    n_high_eco_scen[i] = nhes\n",
    "    n_both_scen[i] = nboth\n",
    "    n_high_inertia_scen[i] = nhi\n",
    "    n_low_pollution_scen[i] = nlp\n",
    "    \n",
    "\n",
    "print('Number of scenarios with reliability of > 0.95 =', n_reliabale_scen)\n",
    "print('Number of scenarios with utility of > 0.2 =',n_high_eco_scen)\n",
    "print('Number of scenarios with reliability of > 0.95 and utility > 0.2 =',n_both_scen)\n",
    "#print('Number of scenarios with inertia of > 0.99 =',n_high_inertia_scen)\n",
    "#print('Number of scenarios with pollution of < Critical point =',n_low_pollution_scen)\n",
    "#print(critical_scen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eker 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pcritical = pd.read_csv('Pcrit(Eker)_50solutions(30.3.2021).csv')\n",
    "#Pcritical.describe()\n",
    "\n",
    "Pcriti = np.zeros((nn,ss))\n",
    "ind = 0\n",
    "for j in range(nn):\n",
    "    for p in range(ss):\n",
    "        Pcriti[j][p] = Pcritical['Pcrit'][ind]\n",
    "        ind += 1\n",
    "    \n",
    "#Pcriti[50][999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Robustness analysis --> C\n",
    "Calculating how many scenarios has \n",
    "    B.1) reliability > 0.8 \n",
    "    B.2) Utility > 0.2/0.1 ?\n",
    "    B.3) Both a and b.\n",
    "\n",
    "\"\"\"\n",
    "n_reliabale_scen = np.zeros((nn,))\n",
    "n_high_eco_scen = np.zeros((nn,))\n",
    "n_both_scen = np.zeros((nn,))\n",
    "n_high_inertia_scen = np.zeros((nn,))\n",
    "n_low_pollution_scen = np.zeros((nn,))\n",
    "#critical_scen = []\n",
    "\n",
    "\n",
    "for i in range(nn): \n",
    "    nrs = 0\n",
    "    nhes = 0\n",
    "    nboth = 0\n",
    "    nhi = 0\n",
    "    nlp = 0\n",
    "    for p in range(ss):\n",
    "        if nnReliability[i+50][p]>.8: #A.1\n",
    "            nrs += 1\n",
    "        #else:\n",
    "        #    critical_scen.append(np.array([p+1, b[p], q[p], mean[p], stdev[p], delta[p]]) )  \n",
    "        if nnUtility[i+50][p]>0.2: #A.2\n",
    "            nhes += 1\n",
    "        if nnReliability[i+50][p]>0.8 and nnUtility[i+50][p]>0.2: #A.3\n",
    "            nboth += 1\n",
    "        if nnInertia[i+50][p]>0.99:\n",
    "            nhi += 1   \n",
    "        if nnPollution[i+50][p]<Pcriti[i][p]:\n",
    "            nlp += 1\n",
    "            \n",
    "    n_reliabale_scen[i] = nrs   \n",
    "    n_high_eco_scen[i] = nhes\n",
    "    n_both_scen[i] = nboth\n",
    "    n_high_inertia_scen[i] = nhi\n",
    "    n_low_pollution_scen[i] = nlp\n",
    "    \n",
    "\n",
    "print('Number of scenarios with reliability of > 0.95 =', n_reliabale_scen)\n",
    "print('Number of scenarios with utility of > 0.2 =',n_high_eco_scen)\n",
    "print('Number of scenarios with reliability of > 0.95 and utility > 0.2 =',n_both_scen)\n",
    "#print('Number of scenarios with inertia of > 0.99 =',n_high_inertia_scen)\n",
    "#print('Number of scenarios with pollution of < Critical point =',n_low_pollution_scen)\n",
    "#print(critical_scen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('robustness_distributions(Eker).csv', 'w', newline='') as f:\n",
    "    objectives = ['Utility', 'Pollution', 'Inertia', 'Reliability', 'group', 'rank'\n",
    "                 ]\n",
    "    thewriter = csv.DictWriter(f, fieldnames=objectives)\n",
    "    \n",
    "    thewriter.writeheader()\n",
    "    \n",
    "    array = n_reliabale_scen/1000\n",
    "    temp = array.argsort()\n",
    "    ranks = np.empty_like(temp)\n",
    "    ranks[temp] = np.arange(len(array))\n",
    "\n",
    "    for i in range(nn):\n",
    "        thewriter.writerow({'Utility' : n_high_eco_scen[i]/1000, 'Pollution' : n_low_pollution_scen[i]/1000, 'Inertia' : n_high_inertia_scen[i]/1000, 'Reliability' : n_reliabale_scen[i]/1000, 'group' : groups[i],'rank' : ranks[i]\n",
    "                               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Robustness_distributions_Eker = pd.read_csv('robustness_distributions(Eker).csv')\n",
    "Robustness_distributions_Eker.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
